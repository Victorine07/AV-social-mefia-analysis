,comment
0,for the example of self driving cars even with accidents we can start to prevent these in the future by improving the underlying algorithms at some point if self driving cars take off then were giving more control to algorithms to run a big aspect of our lives however it is quite likely that the total number of accidents gets reduced compared to having human only drivers how do we then approach this ethical dilemma giving up control to a black box black box for most people who dont know whats gone into it and potentially hurting individuals in exchange for improving the lives of people in general i would naively argue its worth convincing society that this is okay because it will save lives but really is it
1,welcome do you foresee the development of some form of standardized ethical framework or procedural framework for training dataset developmentutilization that addresses some of the more common inherited bias issues with machine learning
2,i hear a lot of fear mongering and complaints about algorithms and ai in the press but few solutions i think the problem is solvable we dont want to create excessive algo skepticism some level of caution is warranted but too much fear mongering i do believe we can control how ai will impact us we need a number of checks and balances in place i proposed a bill of rights in my book for the same the main pillars are listed below in response to a later answer transparency audits user control etc also if we are going to reject algo decisions we should ask whats teh alternative humans are highly error prone as well heres what i say in my book i say that the biggest cause for concern in my opinion is not that algorithms have biases humans do too and on average well designed algorithms are less biased but that we are more susceptible to biases in algorithms than in humans because algorithms deployed by large tech platforms like google and facebook instantaneously touch billions of people the scale of their impact exceeds any damage that can be caused by biases introduced by human decision makers meaning that a biased judge might affect the lives of say people but a biased algorithm used to guide sentencing decisions of judges all over the us will affect the lives of several hundred thousands of people so i believe we should raise the bar a bit more for algos than for humans when deploying them in socially critical settings subject them to an audit by a team other than the one that built the ai then deploy them while i say we should raise the bar i am against some fear mongering going on in fact in an article i argued that i would argue that its not acceptable to reject todays ai due to perceived ethical issues why ironically i believe it might be unethical to do so at its core there is a meta ethics issue here how can we advocate halting the deployment of a technology solely because of a small chance of failure when we know that ai technologies harnessed today could definitely save millions of people see more about this viewpoint here dilemmas must not halt the rollout of ai
3,this is an important issue i feel that we should take concerns with algorithms and ai seriously but we should recognize that its often better than the alternative for example in my book a humans guide to machine intelligence i say that the biggest cause for concern in my opinion is not that algorithms have biases humans do too and on average well designed algorithms are less biased but that we are more susceptible to biases in algorithms than in humans because algorithms deployed by large tech platforms like google and facebook instantaneously touch billions of people the scale of their impact exceeds any damage that can be caused by biases introduced by human decision makers meaning that a biased judge might affect the lives of say people but a biased algorithm used to guide sentencing decisions of judges all over the us will affect the lives of several hundred thousands of people so i believe we should raise the bar a bit more for algos than for humans when deploying them in socially critical settings subject them to an audit by a team other than the one that built the ai then deploy them while i say we should raise the bar i am against some fear mongering going on in fact in an article i argued that i would argue that its not acceptable to reject todays ai due to perceived ethical issues why ironically i believe it might be unethical to do so at its core there is a meta ethics issue here how can we advocate halting the deployment of a technology solely because of a small chance of failure when we know that ai technologies harnessed today could definitely save millions of people see more about this viewpoint here dilemmas must not halt the rollout of ai
4,thank you for your reply this makes wonder now while it may be far in the future for now do you think ai will end up limiting our freedom of choice for example even with ad and moviebook recommendation algorithms machines already limit the choices were exposed to and likely to make many times they do recommend things we end up liking more than things weve chosen completely independently in a future where ai advises politicians and handles problems like optimizing a health care act to provide the highest quality lowest cost care to everyone in a country balancing also perceived sense of fairness from the population politicians really do not have many choices left to make or debate an ai analyzing a court case will one day be able to make a less biased decision than a judge or jury etc by extension democracy and society as we know it would change drastically as ais reasoning overtakes our own even just for specialized tasks how do we balance the ethical obligation to use the best tools we have to make decisions that have the best possible outcome for everyone involved and the will to preserve our freedom of agencychoiceideology
5,thank you for your response i was just trying to understand the sub so i appreciate the answer and you being civil about it there is a lot of confusion about veganism not saying by you people will reduce consumption as you have said due to reasons like health environment etc but to eliminate completely and become vegan it needs to be ethical reasons it makes sense that there would be a lot of people here who vastly reduce animal product consumption but to actually be vegan they would need to share the vegan ethics towards animals so i understand that this sub isnt necessarily filled with vegans again thank you for the response
6,anti science yeah no fuck you not being signed up to your ethical agenda is not anti science animal products increase risk of death from multiple causes by anywhere near million deaths a year no so point does not apply since you mentioned the who their website roomquestions and answersitemcancer carcinogenicity of the consumption of red meat and processed meat says the number might be point does apply its also affecting climate change climate change is point your claim here is actually about air pollution from arable farming as far as i can tell however that is a fair point that i hadnt considered and is another issue with intensive meat production that requires large amounts of cropland to support it id say that the answer there is more responsible arable farming to grow those crops though point does apply an animal based diet is more expensive people arent spending of their income on meat your second im not reading one from vegan food and living thats clearly going to be biased link also says could be cheaper but the main difference here is that there is no meat dependency that is forcing people into that choice they are choosing to spend that extra money because they like eating that food point does apply to all of food production greenhouse gases are from animal products while providing nowhere near of the calories and what proportion of that is from intensive farming you didnt even contest the point i made there so my question maybe should have been worded differently i assume people are already reducing intake of animal products based on their morals and why they are here some even vegan so im guessing this is a vegan friendly place i guess that would have been a better thing for me to say yes it absolutely would have been a better thing for you to say there is an analogy to be made here like car dependent sprawl and stroads in city centres intensive farming for meat production is a bad thing with negative effects and should be discouraged many people can improve their lives and environmental impact by reducing how much meat they eat veganism is analogous to some ridiculous ban all cars immediately and you shouldnt use asphalt roads because theyre car products position edit and now look youve dragged me into a stupid argument about this unrelated issue im going to stop replying under this post now
7,yeah no fuck you not being signed up to your ethical agenda is not anti science not being vegan doesnt make you anti science and i havent claimed that it does denying those things apply to animal products is though because science tellsshows us that they do apply by anywhere near million deaths a year no so point does not apply since you mentioned the who their website says the number might be so deaths only matter if they are exactly million you also have to look at indirect deaths through heart disease etc which consuming animal products increases the likelihoodrisk of plus ptsdsuicide of slaughterhouse workers etc climate change is point your claim here is actually about air pollution from arable farming as far as i can tell however that is a fair point that i hadnt considered and is another issue with intensive meat production that requires large amounts of cropland to support it id say that the answer there is more responsible arable farming to grow those crops though you cant do it responsibly on a large scale when using such an inefficient food source animal products though even if you do it as best as possible for animal products you are still growing multiple times the number of crops you would need to if you didnt consume animal products its still a big impact people arent spending of their income on meat your second im not reading one from vegan food and living thats clearly going to be biased link also says could be cheaper but the main difference here is that there is no meat dependency that is forcing people into that choice they are choosing to spend that extra money because they like eating that food but that doesnt matter maybe i worded it weirdly or you are misunderstanding it doesnt matter if the figures are exactly the same the arguments the reasoning is the same apologies if i caused the confusion i was trying to say that the arguments are the same i wouldnt say its meat dependency in the same way as cars but up until a few years ago that would be considered the case veganism is becoming increasingly easy something it seems like people in this sub wants for cars just because veganism is further along doesnt mean it isnt comparable i assume you wouldnt abandon your principles regarding cars if other modes of transport become easier and also the link uses a study its not just the opinion when directly compared it is cheaper than the cheapest meat but it can be a similar price if someone goes expensive on the vegan products meat is not cheaper than the cheapest plants even calorie for calorie or protein to protein and what proportion of that is from intensive farming you didnt even contest the point i made there intensive farming makes up the vast majority of animal products it has to with the amount of people in the world if you are against intensive farming but for the consumption of animal products then you either think that only some people should be allowed them or everyone has to be limited to like portion a week veganism is analogous to some ridiculous ban all cars immediately and you shouldnt use asphalt roads because theyre car products position its not at all veganism is against animal abuse stopping consuming animal products only because of the environment would be your example not veganism edit and now look youve dragged me into a stupid argument about this unrelated issue im going to stop replying under this post now i stated a fact and asked a question about this sub which you decided to respond to by denying science dont see how i dragged you into it
8,i hate these types of dilemmas this is more of a difference between men and women thought process that an ethical dilemma
9,im not asking who youd want it to pick to kill btw im asking ethically whats right
10,the trolly problem is largely imagined i think people thought automating elevators would create this huge ethical dilemma but the reality is the cars wont go faster than is safe and the minute something is mechanically wrong theyll just pull off to the side and stop the majority of accidents that are like turn away from accidents and not oh crap stop accidents are just because the driver wasnt paying attention and didnt realize it was an oh crap stop accident until it was too late computers will just be able to stop the car before its a plow into the kid or the car problem
11,as humans we sometimes have to make the same decisions i dont see why a decision made by a ai that results in the same outcome most likely less lives lost is any more or less ethical then when a human makes the decision
12,my issue is that people want to make it into a different sort of trolley problem one where the decision isnt between people on separate tracks it is between the people on the tracks and the people on the trolley the question i have is people are freaking out over if people are in the middle of the road and the car an either hit them or swerve and kill the driver that is absurd no one would buy a car that is going to intentionally kill the driver regardless of if it is arguably the ethical solution if those people are in the road where they shouldnt be then bad things happen if a human being was driving on a bridge with no railings and people suddenly emerged in front of them the human would slam on the brakes but wouldnt swerve off the edge killing themselves they would do everything they could not to hit the people ie slamming on the breaks but those people would get hit if the people are supposed to be in the road like say in a cross walk when they have the right of way and a self driving car is barreling toward them then there are bigger concerns about the technology than whether or not it will make the ethical choice i just cant stand the discussion surrounding self driving cars because it just reeks of people trying to be philosophical when the questions arent that complicated
13,agree with this their are huge legal and ethical barriers to removing a human operator who is responsible for the car another thing to add to your list is how autonomous cars will balance the safety of other road users pedestrians and its occupants simply comparing bulk numbers of people injured and killed wont work is it ethical to sell a car that would potentially endanger you by swerving away from a group people in the road should the car being more willing to swerve away from pedestrians in a potentially dangerous maneuver if you are the sole occupant
14,there is no ethically right answer but if you would save yourself if you had been driving why demonize the machine for making the same choice
15,thus the ethical dilemma its not a math problem we humans are able to do math but can a computer do ethics
16,im writing a thesis on this for class using this exact same argument there has been an ethics panel in germany that has made a very similar conclusion valuing human life must take precedence above all else the question is where do we draw the line is it quantitative if there are two pedestrians is it fair to kill just one passenger instead its the trolley car debate on steroids another problem is that research so far indicates that the overwhelming majority of the public wants these cars they just dont want to pay the price with their own lives when someone else could take the fall its a catch that will take government intervention to solve because the automotive industry simply catering to consumer demand could create the scenario that the more you pay the more safety features are added to the car to protect you the passenger over everyone else my thesis in a nutshell it still needs quite a bit of work but this is possibly the most relevant modern day take on utilitarian principles yet sources dobrindt alexander federal government adopts action plan on automated driving bmvi federal government adopts action plan on automated driving august accessed march http dobrindt federal government action plan automated drivinghtml emerging technology from the arkhiv why self driving cars must be programmed to kill mit technology review october accessed march self driving cars must be programmed to kill knight will self driving cars get a code of ethics mit technology review july accessed march to help self driving cars make ethical decisions tuffley david at last the worlds first ethical guidelines for driverless cars the conversation september accessed march http theconversationcomat last the worlds first ethical guidelines for driverless cars
17,from the linked wikipedia page problems analogous to the trolley problem arise in the design of autonomous cars in situations where the cars software is forced during a potential crash scenario to choose between multiple courses of action sometimes including options which include the death of the cars occupants all of which may cause harm a platform called moral machine was created by mit media lab to allow the public to express their opinions on what decisions autonomous vehicles should make in scenarios that use the trolley problem paradigm other approaches make use of virtual reality to assess human behavior in experimental settings in the government of germany constituted an ethical commission that addressed the implications of autonomous driving as a result the commission defined rules for autonomous and connected driving which will be obligatory for upcoming laws regarding the production of autonomous cars
18,doesnt even have to be terminally ill people if harvesting the organs of one person off the street can save the lives of people then the very basic ethical reasoning this poster uses says we should kill them all and harvest their organs
19,has anyone suggested that the cars might just simply stop when there is any kind of ethical dilemma
20,doesnt even have to be terminally ill people if harvesting the organs of one person off the street can save the lives of people then the very basic ethical reasoning this poster uses says we should kill them all and harvest their organs no because that decision is not ours to make but that persons in case of the collision the car driver is the one making the choice that being said donating organs is legal using organs of dead people is legal and euthanasia should be legal so you can almost do that
21,its interesting as a thought experiment but has no real pragmatic application thats about it a lot of people like to play philosopher but the reality is the cars just wont get into situations where they have to make these weird ethical dilemmas ive been driving for years and never once had to decide between the blind man walking his dog and the bus stop full of teenagers it just doesnt happen now and will happen less when the cars can pay a million times better attention to the roadway than i can
22,i get that its illegal and probably unethical to fall asleep in a self driving car and thats why people get mad at it but is it really that different from being awake and just not paying attention and isnt that the whole point of a self driving car
23,if the doctor in question was on the board deciding about the priority on the waiting list then its highly unethical and illegal
24,thats exactly the problem it quite obviously was gratitude but was it reciprocal its fine to pay the bills as you say for a friend but when there is even a small chance for the appearance of ethical impropriety most professionals friends or not know better than to accept such a gift it doesnt look good even if its totally innocent so they know to avoid anything that would give even the slightest hint of reciprocity that surgeon should have known better most practices give ethical training all the time and its part of his degree to begin with this is what makes me skeptical he knew better
25,yes thank you i dont understand how anyone thinks its ethical to hinder the growth of self driving cars because you cant assign blame if we can save even life with them its worth it
26,honestly this sub is kind of insane when it comes to this stuff this us the scariest thing ever not because of people dying in traffic but who is to blame who does the ethical responsibility for that decision test on the field of ethics has asked for centuries whose life is worth preserving in the railtrain scenario and now car producers just answer based on profit since nobody would buy a car that kills its driver it will always swerve into pedestrians to save the driver
27,there is no proof that this will be better than human drivers there are also ethical concerns
28,telling people to accept that self driving cars will kill people is an ethical and moral nonsense there are laws and punishments for being a bad driver bad driving includes killing people which is punished the only way autonomous vehicles will become better drivers will be if that regime of punishment applies to the vehicles or their corporate owners until self driving cars are better drivers in an environment of human drivers they will not really be better drivers at all the entire idea that underdeveloped models will most likely be an improvement is a fundamentally flawed premise purely because the standard has been set by human drivers already
29,tldr scary to use humans to test new tech the world is desensitized to loss of human life similar to companies under the fda autonomous vehicle companies should prove their products are safe and effective before using you might die but thats okay slogan this is terrifying ideology for example a woman killed her newborn in a town elsewhere in my state by shaking it because it wouldnt eat the ct scan showed six blunt force injuries on the brain everyone finds this abhorrent how is abortion not on the same page a human fetus is a human too i digresspeople die in cars and that is a terrible thing to happen someone dies in an autonomous vehicle and thats for the cause someone getting killed is such a desensitized event in the world now that the selling point for future tech egautonomous vehicles is that some people will die during testing and that is okay some people died at sandy hook elementary was that okay in order to improve security at schools no and if you think it was you extremely need to rethink some things about yourself heres the reality of the situation loss of life is never okay every person is unique and wonderful and beautifully made never should there be technology or ideas that we explore where human mortality is not the utmost concern autonomous vehicles shouldnt be sold under the notion that youre an early user so you may die but thats a sacrifice we are willing to make because our product is better at driving than you a la lord farquad youtubehikuxfcsreu its nonsensical death comes for us all thats the consequence of our sin yes we accept that but sacrificing people for technological advancements isnt that illegal not to mention hugely unethical enmwikipediaorgwikiunethical_human_experimentation read the united states section the kefauver harris drug amendment to the federal food drug consumer act requires companies to prove safety and effectiveness of their products theyre prioritizing human life and wellness now as law requires why arent autonomous car companies trying to sell their products with the focal selling point being the best safety and effectiveness too surely this is being investigated surely the autonomous vehicle companies arent experimenting why should we accept a product that isnt proven effective and safe in the highest degree i dont think we should accept it not until its been shown to be safe there are good and bad drivers on the roads every time we get in a car we risk our lives but we take penicillin because we know its been proven effective and safe and labeled as such i drive my particular car because its been proven safe and effective at keeping me that way i buckle my seatbelt for the same reason its proven to be safe and effective why shouldnt an autonomous vehicle be subject to the same parameters im okay with downvotes felt like adding my two pence this is a hot topic rall we need to be discussing this
30,i think one of the most interesting ethical dilemmas that arises from autonomous vehicles is when a decision has to be made between two highly undesirable outcomes and its left to pure calculation on the machines to make a decision regarding the outcome example you are driving an autonomous vehicle a hazard presents itself where your car must now decide whether to a sacrifice you the driver to save the other person or b sacrifice the other person to save you an autonomous vehicle would have to be programmed with parameters to make this decision if the hazard is a child and youre a middle aged person should not the vehicle sacrifice you would you get into a vehicle that you know could sacrifice you given certain parameters equally is it ethical that one could buy an autonomous vehicle that guarantees not to sacrifice its driver this is in my view going to be one of the biggest hinderances in the uptake of autonomous vehicles
31,if self driving cars achieve an equal or better safety record than the average human then no i dont see why the occupants of a self driving car should be prepared to assume control any more than train passengers are people get killed every day on the roads but we consider that an acceptable risk due to the relative infrequency and benefit to society that cars provide self driving vehicles are no different in fact humans do a pretty shitty job of driving on average so from an ethical standpoint we should feel compelled to get them out of the driving seat crashstatsnhtsadotgovapipublicviewpublication
32,a dirty camera means theres no input image that didnt have anything to do with adversarial attacks lol same with fog and blizzard adversarial image attacks are literally just the original image with noise added in feel free to review the research to refresh your memory an ml system ultimately needs to be able to think like a human because were not going to be able to train every situation and the public isnt going to want to get into a car they have no control over if they think its going to kill them when weather conditions arent as favorable as the weather the car was trained in it seems rather ethically dubious to widely release a technology with such glaring issues inherent to the very system the tech is built on
33,just the original image with noise not just any noise youre the one who needs to refresh your memory a dirty camera means theres no input image so if all the cameras somehow became dirty you slow down stop hand off controls to the driver ive been driving tesla for a while now and none of the cameras needed any cleaning yet let alone being completely blind all of them at the same time youre truly grasping at straws here an ml system ultimately needs to be able to think like a human no it doesnt were not going to be able to train every situation thats not how it works modern neural nets compress and generalize knowledge you dont need to train it on literally every road in the world to be useful and the public isnt going to want to get into a car they have no control over if they think its going to kill them again youre making obviously false claims teslas fsd alone has k drivers using it and how many of them have died because of fsd it seems rather ethically dubious to widely release a technology with such glaring issues you have no problem with regular cars that are driven by humans who regularly get drunk get high look at their smartphones text pass out due to health problems dont pay attention somehow you ignore these glaring issues thousand deaths per year in the us alone data and you know why because you accept a certain level of risk just like everyone else
34,how do they acquire consent via other drivers on the road who are subsequently forced into this study seems incredibly unethical
35,cops will be irrelevant car just drives you straight to jail instead you spend the whole time freaking out what was it this time defaulted on your mortgage and the bank is taking your kidneys or maybe you missed a traffic ticket and they decided to remove you from circulation its not your fault you cant afford software update and your permarental took a suboptemized traffic route and caused a few milliseconds delay to someone elses commute every second that passes you feel a scream rising in your throat you press the door button but it refuses to respond the bulletproof windows of the tesla permarental designed to protect you from gang violence keeping you from throwing yourself into the road you desperately wish you had bought the standard package so you would have an actual key and not a remote start button just so you could slit your own throat with it the world passes by completely unaware of your growing terror the walls of the car begin to close in as your future as a test subject for a pharmaceutical as a more ethical replacement to animals becomes clear to you its ironic really you protested animal testing in college you see the jail now the drive in beckons as your car makes the final adjustment and prepares to leave you to your fate your phone vibrates the uber bailbondtm app is offering to bail you for ten thousand plus adjusted course mileage surcharge you agree but you only have three hundred bucks left after your apple ieye needed to be replaced last month due to manufacturers fault you open up the dao loan exchange and apply opting for twenty thousand to cover conversions and tumbling to ensure you dont end up with tainted currency the smart contract sits uncompleted as your journey comes to its end your life flashes before your eyes as the money is approved and your account emptied to secure your freedom minus twenty dollar first time credit of course by the time your mostly uneventful life has been played to you the car is almost at its original destination you get out of the car and make your way inside the featureless dormitory you reside in its three foot efficiency elevator depositing you at your tiny quarters you strip off your clothes as the door slides shut behind you the chill of the room biting at you as you do youd have a shower but its been broken for months a slow dripping that fills your meager dwelling with mold and rot the arbitration clause and abdication of rights agreement leaving you without recourse with the corporation that runs the facility you climb into bed the sewn rags you call a blanket wet with moisture that only serves to further your discomfort your ieye playing videos of the latest apple appliances and updating you on the latest celebrity news sleep is fleeting and dreams are corrupted by commercials all that is certain to you is that you will awake into the world and hope your job hasnt been replaced by a machine ok im done
36,its not just ethically who is in control but given that everybody with a self driving car will need to buy insurance then its one of the most cost effective ways for owners of self driving cars to take out insurance who is going to get the better deal a billion pound car manufacturer or you on your phone to somebody who is reading a script they likely have zero legal training to understand and even if they did theyre employed to rip you off in the ideal world the government would be in charge of taking our insurance policies for us all because we have a democratic say in what that decision they make but the second best option is for the car manufacturers
37,you make good points and this really highlights how far away from actual self driving cars we are elon musk has spent years selling us this idea when all theyve got is cruise control that can follow lanes and even if we had the technology for cars to drive themselves were still years from resolving the ethical issues
38,tbh at this point weve had decades to resolve the ethical issues im starting to think its going to end up being done how it always gets done just doing it anyway and then seeing what enough people get angry enough or die from to make laws about all part of the process
39,there are other ethical situations where the pedestrian isnt at fault what if a car coming the opposite way swerves right in front of you at the last second your self driving car can brake all it wants but it may have to swerve in order to avoid the collision now what if there are pedestrians on the sidewalk of the road what would probably happen in that situation is that the car will allow the collision to happen since cars are designed for hitting each other and there would be nothing to protect swerving into the pedestrians that seems like the logical choice but there is another argument to be made too should the car protect the driver at all costs the driver is surrendering themselves and giving all trust and control in this car would it be ethical for it to allow the driver to be hurt over other people who arent involved with the car the reason people are talking about these hypothetical situations is because they will have to be decided before the situation becomes a reality these conditions will have to be explicitly set in the rules logic this isnt an area where we can say well see what happens these kind of decisions will have to be explicitly laid out and i think thats what people get hung up on a programmer will have to sit down and make the decision let my driver get hurt let the other driver get hurt let the bystanders get hurt an irobot model can even be applied where collision avoidance is based on a statistical survival model
40,im not convinced someone will need to map out all the different situations like these the ethical decision would still be made by abstention the car will presumably know about its surroundings youtubecsvtjbawbk t now look at the simple logic swerve to avoid collision the car would know that theres a pedestrian there because thats probably some lower level stuff exposed to the ai module if the programmer didnt add a except dont actually swerve is this case is true rule they made an ethical decision at that point they could check if a person is there but didnt
41,why does it need to identify that its a person in the google video pedestrians and cyclist are automatically identified in a consumer sdc that will presumably happen at a very low level maybe even silicon for example googles project tango tctechcrunchfileswordpresscomcameras_tangopng wh has x on board computer vision processors that do the heavy lifting and number crunching that data is then exposed to the higher levels my point and the ethical situation is that the ai will probably already know whats in the swerve area since it will probably be identified at a low level a programmer may end up intentionally or unintentionally ignoring what is known to the car
